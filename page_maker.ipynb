{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jack Pope\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "C:\\Users\\Jack Pope\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "C:\\Users\\Jack Pope\\AppData\\Roaming\\Python\\Python39\\site-packages\\matplotlib\\projections\\__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import argparse\n",
    "import glob\n",
    "import requests\n",
    "import astropy.units as u\n",
    "from astropy.io import fits as pyfits\n",
    "import matplotlib.pyplot as plt\n",
    "from urllib.request import urlopen\n",
    "from astropy.table import Table\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.wcs import WCS\n",
    "from astropy.time import Time\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "from PIL import Image, ImageDraw, ImageFont"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing File and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded ztf_transients.csv\n"
     ]
    }
   ],
   "source": [
    "url = \"https://sites.astro.caltech.edu/ztf/bts/explorer.php?f=s&subsample=trans&classstring=&classexclude=&ztflink=lasair&lastdet=&startsavedate=&startpeakdate=&startra=&startdec=&startz=&startdur=&startrise=&startfade=&startpeakmag=&startabsmag=&starthostabs=&starthostcol=&startb=&startav=&endsavedate=&endpeakdate=&endra=&enddec=&endz=&enddur=&endrise=&endfade=&endpeakmag=19.0&endabsmag=&endhostabs=&endhostcol=&endb=&endav=&format=csv\"\n",
    "\n",
    "csv_filename = 'ztf_transients.csv'\n",
    "\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    with open(csv_filename, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    print(f\"Downloaded {csv_filename}\")\n",
    "\n",
    "transients = pd.read_csv(\"ztf_transients.csv\")\n",
    "\n",
    "num_images = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get List of Transient Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZTFID</th>\n",
       "      <th>IAUID</th>\n",
       "      <th>RA</th>\n",
       "      <th>Dec</th>\n",
       "      <th>peakt</th>\n",
       "      <th>peakfilt</th>\n",
       "      <th>peakmag</th>\n",
       "      <th>peakabs</th>\n",
       "      <th>duration</th>\n",
       "      <th>rise</th>\n",
       "      <th>fade</th>\n",
       "      <th>type</th>\n",
       "      <th>redshift</th>\n",
       "      <th>b</th>\n",
       "      <th>A_V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZTF17aaapufz</td>\n",
       "      <td>AT2016blu</td>\n",
       "      <td>12:35:52.28</td>\n",
       "      <td>+27:55:55.4</td>\n",
       "      <td>1726.75</td>\n",
       "      <td>g</td>\n",
       "      <td>16.4333</td>\n",
       "      <td>-13.87</td>\n",
       "      <td>&gt;2.09</td>\n",
       "      <td>2.09</td>\n",
       "      <td>&gt;0</td>\n",
       "      <td>LBV</td>\n",
       "      <td>0.00261</td>\n",
       "      <td>86.456839</td>\n",
       "      <td>0.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZTF17aaazdba</td>\n",
       "      <td>AT2019azh</td>\n",
       "      <td>08:13:16.95</td>\n",
       "      <td>+22:38:53.9</td>\n",
       "      <td>561.73</td>\n",
       "      <td>g</td>\n",
       "      <td>15.2769</td>\n",
       "      <td>-19.76</td>\n",
       "      <td>66.42</td>\n",
       "      <td>24.318</td>\n",
       "      <td>42.102</td>\n",
       "      <td>TDE</td>\n",
       "      <td>0.022</td>\n",
       "      <td>27.562336</td>\n",
       "      <td>0.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZTF17aabtvsy</td>\n",
       "      <td>SN2022yei</td>\n",
       "      <td>10:35:32.09</td>\n",
       "      <td>+37:38:59.0</td>\n",
       "      <td>1870.99</td>\n",
       "      <td>r</td>\n",
       "      <td>18.0303</td>\n",
       "      <td>-19.41</td>\n",
       "      <td>&gt;34.229</td>\n",
       "      <td>&gt;6.01</td>\n",
       "      <td>28.219</td>\n",
       "      <td>SN Ia</td>\n",
       "      <td>0.06922</td>\n",
       "      <td>59.641962</td>\n",
       "      <td>0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZTF17aacldgo</td>\n",
       "      <td>SN2022zxv</td>\n",
       "      <td>03:09:24.35</td>\n",
       "      <td>-04:53:39.2</td>\n",
       "      <td>1897.75</td>\n",
       "      <td>g</td>\n",
       "      <td>18.7979</td>\n",
       "      <td>-18.91</td>\n",
       "      <td>&gt;8.87</td>\n",
       "      <td>&gt;3.85</td>\n",
       "      <td>&gt;5.02</td>\n",
       "      <td>SN Ia</td>\n",
       "      <td>0.072</td>\n",
       "      <td>-50.332472</td>\n",
       "      <td>0.183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZTF17aacpbmv</td>\n",
       "      <td>SN2023wtm</td>\n",
       "      <td>03:17:51.82</td>\n",
       "      <td>-00:06:17.8</td>\n",
       "      <td>2261.83</td>\n",
       "      <td>g</td>\n",
       "      <td>17.7727</td>\n",
       "      <td>-17.45</td>\n",
       "      <td>21.11</td>\n",
       "      <td>7.373</td>\n",
       "      <td>13.737</td>\n",
       "      <td>SN Ic</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-45.665483</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8846</th>\n",
       "      <td>ZTF24aahlvgk</td>\n",
       "      <td>SN2024ewu</td>\n",
       "      <td>07:01:04.26</td>\n",
       "      <td>+24:23:22.0</td>\n",
       "      <td>2392.70</td>\n",
       "      <td>g</td>\n",
       "      <td>18.4201</td>\n",
       "      <td>-19.49</td>\n",
       "      <td>&gt;17.897</td>\n",
       "      <td>&gt;2.01</td>\n",
       "      <td>15.887</td>\n",
       "      <td>SN Ia-pec</td>\n",
       "      <td>0.08</td>\n",
       "      <td>12.847346</td>\n",
       "      <td>0.162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8847</th>\n",
       "      <td>ZTF24aahmgvr</td>\n",
       "      <td>SN2024exp</td>\n",
       "      <td>09:44:01.40</td>\n",
       "      <td>-14:54:05.2</td>\n",
       "      <td>2403.75</td>\n",
       "      <td>r</td>\n",
       "      <td>17.1213</td>\n",
       "      <td>-18.65</td>\n",
       "      <td>25.135</td>\n",
       "      <td>8.305</td>\n",
       "      <td>16.83</td>\n",
       "      <td>SN Ia</td>\n",
       "      <td>0.03</td>\n",
       "      <td>28.092871</td>\n",
       "      <td>0.249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8848</th>\n",
       "      <td>ZTF24aahmqzq</td>\n",
       "      <td>SN2024ead</td>\n",
       "      <td>15:47:50.73</td>\n",
       "      <td>-08:25:59.0</td>\n",
       "      <td>2390.98</td>\n",
       "      <td>g</td>\n",
       "      <td>18.2567</td>\n",
       "      <td>-19.26</td>\n",
       "      <td>&gt;10.095</td>\n",
       "      <td>&gt;0.09</td>\n",
       "      <td>&gt;10.005</td>\n",
       "      <td>SN Ia</td>\n",
       "      <td>0.05931</td>\n",
       "      <td>34.424666</td>\n",
       "      <td>0.381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8849</th>\n",
       "      <td>ZTF24aahoihk</td>\n",
       "      <td>SN2024evm</td>\n",
       "      <td>07:52:18.48</td>\n",
       "      <td>+18:08:08.3</td>\n",
       "      <td>2399.65</td>\n",
       "      <td>g</td>\n",
       "      <td>17.4437</td>\n",
       "      <td>-19.41</td>\n",
       "      <td>&gt;20.692</td>\n",
       "      <td>&gt;7.96</td>\n",
       "      <td>12.732</td>\n",
       "      <td>SN Ia</td>\n",
       "      <td>0.05</td>\n",
       "      <td>21.342204</td>\n",
       "      <td>0.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8850</th>\n",
       "      <td>ZTF24aahszxf</td>\n",
       "      <td>SN2024exw</td>\n",
       "      <td>12:13:27.36</td>\n",
       "      <td>+14:46:40.3</td>\n",
       "      <td>2403.82</td>\n",
       "      <td>g</td>\n",
       "      <td>15.0824</td>\n",
       "      <td>-17.42</td>\n",
       "      <td>&gt;41.21</td>\n",
       "      <td>&gt;5.85</td>\n",
       "      <td>35.36</td>\n",
       "      <td>SN II</td>\n",
       "      <td>0.007</td>\n",
       "      <td>74.811027</td>\n",
       "      <td>0.094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8851 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ZTFID      IAUID           RA          Dec    peakt peakfilt  \\\n",
       "0     ZTF17aaapufz  AT2016blu  12:35:52.28  +27:55:55.4  1726.75        g   \n",
       "1     ZTF17aaazdba  AT2019azh  08:13:16.95  +22:38:53.9   561.73        g   \n",
       "2     ZTF17aabtvsy  SN2022yei  10:35:32.09  +37:38:59.0  1870.99        r   \n",
       "3     ZTF17aacldgo  SN2022zxv  03:09:24.35  -04:53:39.2  1897.75        g   \n",
       "4     ZTF17aacpbmv  SN2023wtm  03:17:51.82  -00:06:17.8  2261.83        g   \n",
       "...            ...        ...          ...          ...      ...      ...   \n",
       "8846  ZTF24aahlvgk  SN2024ewu  07:01:04.26  +24:23:22.0  2392.70        g   \n",
       "8847  ZTF24aahmgvr  SN2024exp  09:44:01.40  -14:54:05.2  2403.75        r   \n",
       "8848  ZTF24aahmqzq  SN2024ead  15:47:50.73  -08:25:59.0  2390.98        g   \n",
       "8849  ZTF24aahoihk  SN2024evm  07:52:18.48  +18:08:08.3  2399.65        g   \n",
       "8850  ZTF24aahszxf  SN2024exw  12:13:27.36  +14:46:40.3  2403.82        g   \n",
       "\n",
       "      peakmag peakabs duration    rise     fade       type redshift  \\\n",
       "0     16.4333  -13.87    >2.09    2.09       >0        LBV  0.00261   \n",
       "1     15.2769  -19.76    66.42  24.318   42.102        TDE    0.022   \n",
       "2     18.0303  -19.41  >34.229   >6.01   28.219      SN Ia  0.06922   \n",
       "3     18.7979  -18.91    >8.87   >3.85    >5.02      SN Ia    0.072   \n",
       "4     17.7727  -17.45    21.11   7.373   13.737      SN Ic    0.023   \n",
       "...       ...     ...      ...     ...      ...        ...      ...   \n",
       "8846  18.4201  -19.49  >17.897   >2.01   15.887  SN Ia-pec     0.08   \n",
       "8847  17.1213  -18.65   25.135   8.305    16.83      SN Ia     0.03   \n",
       "8848  18.2567  -19.26  >10.095   >0.09  >10.005      SN Ia  0.05931   \n",
       "8849  17.4437  -19.41  >20.692   >7.96   12.732      SN Ia     0.05   \n",
       "8850  15.0824  -17.42   >41.21   >5.85    35.36      SN II    0.007   \n",
       "\n",
       "              b    A_V  \n",
       "0     86.456839  0.048  \n",
       "1     27.562336  0.122  \n",
       "2     59.641962  0.053  \n",
       "3    -50.332472  0.183  \n",
       "4    -45.665483  0.200  \n",
       "...         ...    ...  \n",
       "8846  12.847346  0.162  \n",
       "8847  28.092871  0.249  \n",
       "8848  34.424666  0.381  \n",
       "8849  21.342204  0.142  \n",
       "8850  74.811027  0.094  \n",
       "\n",
       "[8851 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "num_instances = len(transients['ZTFID'])\n",
    "nested_list = []\n",
    "\n",
    "for i in range(num_instances):\n",
    "    row = []\n",
    "    for key in transients:\n",
    "        row.append(transients[key][i])\n",
    "    nested_list.append(row) \n",
    "\n",
    "for i in range(2):\n",
    "    object = nested_list[i]\n",
    "    name = object[0]\n",
    "    ra = object[2]\n",
    "    dec = object[3]\n",
    "    skyguy = SkyCoord(ra = ra, dec = dec, unit=(u.hourangle, u.deg))    \n",
    "\n",
    "nested_list\n",
    "transients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.coordinates import SkyCoord\n",
    "from ztfquery.utils import stamps\n",
    "import io\n",
    "\n",
    "def plot_ls_cutout(ddir, name, c):\n",
    "    \"\"\" Plot cutout from Legacy Survey \"\"\"\n",
    "\n",
    "    ra = c.ra.deg\n",
    "    dec = c.dec.deg\n",
    "\n",
    "    if dec < 0:\n",
    "        decsign = \"-\"\n",
    "    else: \n",
    "        decsign = \"+\"\n",
    "\n",
    "    fname = ddir + \"\\\\%s_legsurv.png\"%name\n",
    "    if os.path.isfile(fname)==False:\n",
    "        url = \"http://legacysurvey.org/viewer/cutout.jpg?ra=%s&dec=%s&layer=ls-dr9&pixscale=0.05&bands=grz\" %(ra,dec)\n",
    "        plt.figure(figsize=(2.1,2.1), dpi=120)\n",
    "        try:\n",
    "            r = requests.get(url)\n",
    "            plt.imshow(Image.open(io.BytesIO(r.content)))\n",
    "            plt.title(\"LegSurv DR9\", fontsize = 12)\n",
    "            plt.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(fname, bbox_inches=\"tight\")\n",
    "        except Exception as e:\n",
    "            # Print the exception to understand what went wrong\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return None\n",
    "        # you want to save it anyway so you don't do this over and over again\n",
    "        plt.close()\n",
    "        \n",
    "    return fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ps1_cutout(ddir, name, c, arcsec_width=12):\n",
    "    \"\"\"\n",
    "    Plot cutout from Pan-STARRS.\n",
    "\n",
    "    Parameters:\n",
    "    - ddir: Directory to save the image.\n",
    "    - name: Name for the image file.\n",
    "    - ra: Right ascension of the target.\n",
    "    - dec: Declination of the target.\n",
    "    - arcsec_width: Desired width of the image in arcseconds (default is 12 arcseconds).\n",
    "    \"\"\"\n",
    "    ra = c.ra.deg\n",
    "    dec = c.dec.deg\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(ddir):\n",
    "        os.makedirs(ddir)\n",
    "    \n",
    "    # Determine the number of pixels corresponding to the desired arcsecond width\n",
    "    pixels = int((arcsec_width / 60) * 240)\n",
    "    \n",
    "    # Determine the filename for the cutout image\n",
    "    fname = os.path.join(ddir, f\"{name}_ps1.png\")\n",
    "    \n",
    "    # Check if the file already exists\n",
    "    if not os.path.isfile(fname):\n",
    "        try:\n",
    "            # Get the Pan-STARRS stamp image\n",
    "            img = stamps.get_ps_stamp(ra, dec, size=pixels, color=[\"y\", \"g\", \"i\"])\n",
    "            \n",
    "            # Plot and save the image\n",
    "            plt.figure(figsize=(2.1, 2.1), dpi=120)\n",
    "            plt.imshow(np.asarray(img))\n",
    "            plt.title(\"PS1 (y/g/i)\", fontsize=12)\n",
    "            plt.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(fname, bbox_inches=\"tight\")\n",
    "            plt.close()\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to fetch or save Pan-STARRS image for {name}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    return fname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a Row of Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded to: VLASS_dyn_summary.php\n"
     ]
    }
   ],
   "source": [
    "import vlass_search\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "def generate_row(name, c, image_dir='images'):\n",
    "    \"\"\"\n",
    "    Generates a row of VLASS PNGs at a given sky coordinate\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    name: name of the source\n",
    "    c: coordinates as SkyCoord object\n",
    "    -----------\n",
    "    \"\"\"\n",
    "    try:\n",
    "        images, epochs, dates = vlass_search.run_search(name, c)\n",
    "    except HTTPError as e:\n",
    "        if e.code == 404:\n",
    "            print(f\"Error 404: URL not found for {name}\")\n",
    "            images, epochs, dates = ['images/unimaged.png'] * 3, ['NA'] * 3, ['Invalid date'] * 3\n",
    "        else:\n",
    "            raise e\n",
    "    \n",
    "    # Append LS and Pan-STARRS images\n",
    "    images.append(plot_ls_cutout(image_dir, name, c))\n",
    "    images.append(plot_ps1_cutout(image_dir, name, c))\n",
    "    \n",
    "    return {'name': name, 'images': images, 'epochs': epochs, 'vla_dates': dates}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multiple_rows(start, end):\n",
    "\n",
    "    image_paths = []\n",
    "    counter = 1\n",
    "\n",
    "    for i in range(start - 1, end):\n",
    "        name = transients['ZTFID'][i]\n",
    "        ra = transients['RA'][i]\n",
    "        dec = transients['Dec'][i]\n",
    "        ztf_date = transients['peakt'][i]\n",
    "        skyguy = SkyCoord(ra = ra, dec = dec, unit = (u.hourangle, u.deg))\n",
    "        # add date to dictionary items\n",
    "        object_dict = generate_row(name, skyguy)\n",
    "        object_dict['ztf_date'] = ztf_date\n",
    "        image_paths.append(object_dict)\n",
    "        print(f\"Object #{counter} complete!\")\n",
    "        counter += 1\n",
    "\n",
    "    for obj in image_paths:\n",
    "        deltas = []\n",
    "        print(obj)\n",
    "\n",
    "        for x in obj['vla_dates']:\n",
    "            # Convert VLA dates to Julian dates\n",
    "            if x != 'Invalid date':\n",
    "                x = Time(x, format = 'iso')\n",
    "                vla_jd_date = x.jd\n",
    "            else:\n",
    "                vla_jd_date = 'NA'\n",
    "            deltas.append(vla_jd_date)\n",
    "            print(f\"VLA JD Date: {vla_jd_date} (type: {type(vla_jd_date)})\")\n",
    "\n",
    "        obj['ztf_date'] += 2458000\n",
    "        print(f\"ZTF JD Date: {obj['ztf_date']} (type: {type(obj['ztf_date'])})\")\n",
    "\n",
    "        # Ensure the type of ZTF date is float\n",
    "        ztf_jd_date = float(obj['ztf_date'])\n",
    "\n",
    "        for i in range(len(deltas)):\n",
    "            if deltas[i] != 'NA':\n",
    "                deltas[i] = round(deltas[i] - ztf_jd_date, 2)\n",
    "\n",
    "        obj['delta_ts'] = deltas\n",
    "        print(f\"Deltas: {deltas}\")\n",
    "        \n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved as images\\unimaged.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jack Pope\\AppData\\Local\\Temp\\ipykernel_53612\\1552530876.py:23: DeprecationWarning: textsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use textbbox or textlength instead.\n",
      "  text_width, text_height = draw.textsize(text, font=font)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "def create_unimaged_image(save_path):\n",
    "    # Define image size and colors\n",
    "    width, height = 400, 400\n",
    "    background_color = (250, 150, 150)  # Black background\n",
    "    text_color = (255, 255, 255)  # White text\n",
    "\n",
    "    # Create a new image with the specified background color\n",
    "    image = Image.new('RGB', (width, height), color=background_color)\n",
    "\n",
    "    # Get a drawing context\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Load a font\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"RobotoSlab-Regular.ttf\", 20)\n",
    "    except IOError:\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    # Define the text and get its size\n",
    "    text = \"Unimaged\"\n",
    "    text_width, text_height = draw.textsize(text, font=font)\n",
    "\n",
    "    # Calculate the position for the text to be centered\n",
    "    text_x = (width - text_width) / 2\n",
    "    text_y = (height - text_height) / 2\n",
    "\n",
    "    # Add the text to the image\n",
    "    draw.text((text_x, text_y), text, fill=text_color, font=font)\n",
    "\n",
    "    # Save the image\n",
    "    image.save(save_path)\n",
    "    print(f\"Image saved as {save_path}\")\n",
    "\n",
    "# Example usage\n",
    "create_unimaged_image(\"images\\\\unimaged.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_content = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Image Gallery</title>\n",
    "    <link rel=\"stylesheet\" href=\"styles.css\">     \n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"container\">\n",
    "        <h1>Image Gallery</h1>\n",
    "        <div class=\"gallery-header\">\n",
    "            <div class=\"header-item\">Epoch 1</div>\n",
    "            <div class=\"header-item\">Epoch 2</div>\n",
    "            <div class=\"header-item\">Epoch 3</div>\n",
    "            <div class=\"header-item\">Legacy Survey Image</div>\n",
    "            <div class=\"header-item\">Panstarrs Image</div>\n",
    "        </div>\n",
    "        {% for row in images %}\n",
    "        <div class=\"row\">\n",
    "            <div class=\"name\">{{ row['name'] }}</div>\n",
    "            <div class=\"image-row\">\n",
    "                {% for i in range(5) %}\n",
    "                    <div class=\"image-container\">\n",
    "                        <img src=\"{{ row['images'][i] }}\" alt=\"Image\" class=\"gallery-image\">\n",
    "                        {% if i < 3 %}\n",
    "                            {% if row['delta_ts'][i] != 'NA' %}\n",
    "                                <p class=\"delta-t\">{{ row['delta_ts'][i] }} days</p>\n",
    "                            {% else %}\n",
    "                                <p class=\"delta-t\">NA</p>\n",
    "                            {% endif %}\n",
    "                        {% endif %}\n",
    "                    </div>\n",
    "                {% endfor %}\n",
    "            </div>\n",
    "        </div>\n",
    "        {% endfor %}\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML page generated and saved as what.html\n"
     ]
    }
   ],
   "source": [
    "def start_html_page(object_names, template=template_content):\n",
    "    # Set up the Jinja2 environment\n",
    "    env = Environment(loader=FileSystemLoader('.'))\n",
    "\n",
    "    # Create a Jinja2 template from the content\n",
    "    template = env.from_string(template_content)\n",
    "\n",
    "    # List to store rows for each object\n",
    "    rows = []\n",
    "\n",
    "    for name in object_names['ZTFID']:\n",
    "        # Generate a row structure with placeholders\n",
    "        row = {\n",
    "            'name': name,\n",
    "            'images': ['images/placeholder.png'] * 5,  # Placeholder images, adjust as needed\n",
    "            'delta_ts': ['NA'] * 3  # Placeholder delta times, adjust as needed\n",
    "        }\n",
    "        rows.append(row)\n",
    "\n",
    "    # Render the template with the placeholder rows\n",
    "    html_content = template.render(images=rows)\n",
    "\n",
    "    # Define the path to save the HTML file\n",
    "    html_filepath = 'what.html'\n",
    "\n",
    "    # Write the rendered HTML content to the file\n",
    "    with open(html_filepath, 'w') as file:\n",
    "        file.write(html_content)\n",
    "\n",
    "    print(f\"HTML page generated and saved as {html_filepath}\")\n",
    "\n",
    "# Example usage\n",
    "start_html_page(transients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Function to update the HTML file with actual images and delta times\n",
    "def update_html_page(start_row, end_row, html_filepath='ooga_booga.html'):\n",
    "    # Generate the actual image data\n",
    "    image_paths = get_multiple_rows(start_row, end_row)\n",
    "\n",
    "    # Convert the list of dictionaries to a dictionary for faster lookups\n",
    "    image_dict = {item['name']: item for item in image_paths}\n",
    "\n",
    "    # Read the existing HTML file\n",
    "    with open(html_filepath, 'r') as file:\n",
    "        soup = BeautifulSoup(file, 'html.parser')\n",
    "\n",
    "    # Find all rows in the HTML file\n",
    "    rows = soup.find_all('div', class_='row')\n",
    "\n",
    "    for row in rows:\n",
    "        # Get the object name for this row\n",
    "        name = row.find('div', class_='name').text.strip()\n",
    "\n",
    "        # Find the matching data from image_dict\n",
    "        matching_data = image_dict.get(name)\n",
    "\n",
    "        if matching_data:\n",
    "            # Get all image containers in this row\n",
    "            image_containers = row.find_all('div', class_='image-container')\n",
    "            for i, img_container in enumerate(image_containers):\n",
    "                # Replace the placeholder image\n",
    "                img_tag = img_container.find('img')\n",
    "                img_tag['src'] = matching_data['images'][i]\n",
    "\n",
    "                # Replace the placeholder delta_t if it's not the last image\n",
    "                if i < 3:\n",
    "                    delta_t_tag = img_container.find('p', class_='delta-t')\n",
    "                    delta_t_tag.string = f\"{matching_data['delta_ts'][i]} days\" if matching_data['delta_ts'][i] != 'NA' else 'NA'\n",
    "\n",
    "    # Save the updated HTML content back to the file\n",
    "    with open(html_filepath, 'w') as file:\n",
    "        file.write(str(soup))\n",
    "\n",
    "    print(f\"HTML page updated and saved as {html_filepath}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def update_html_page(start_row, end_row, html_filepath='what.html'):\n",
    "    # Generate the actual image data\n",
    "    image_paths = get_multiple_rows(start_row, end_row)\n",
    "\n",
    "    # Convert the list of dictionaries to a dictionary for faster lookups\n",
    "    image_dict = {item['name']: item for item in image_paths}\n",
    "\n",
    "    # Read the existing HTML file\n",
    "    with open(html_filepath, 'r') as file:\n",
    "        soup = BeautifulSoup(file, 'html.parser')\n",
    "\n",
    "    # Find all rows in the HTML file\n",
    "    rows = soup.find_all('div', class_='row')\n",
    "\n",
    "    for row in rows:\n",
    "        # Get the object name for this row\n",
    "        name = row.find('div', class_='name').text.strip()\n",
    "\n",
    "        # Find the matching data from image_dict\n",
    "        matching_data = image_dict.get(name)\n",
    "\n",
    "        if matching_data:\n",
    "            # Get all image containers in this row\n",
    "            image_containers = row.find_all('div', class_='image-container')\n",
    "            for i, img_container in enumerate(image_containers):\n",
    "                # Replace the placeholder image\n",
    "                img_tag = img_container.find('img')\n",
    "                img_tag['src'] = matching_data['images'][i]\n",
    "\n",
    "                # Replace the placeholder delta_t if it's not the last image\n",
    "                if i < 3:\n",
    "                    delta_t_tag = img_container.find('p', class_='delta-t')\n",
    "                    print(f\"Updating delta_t for image {i}: {matching_data['delta_ts'][i]}\")\n",
    "                    delta_t_tag.string = f\"{matching_data['delta_ts'][i]} days\" if matching_data['delta_ts'][i] != 'NA' else 'NA'\n",
    "\n",
    "    # Save the updated HTML content back to the file\n",
    "    with open(html_filepath, 'w') as file:\n",
    "        file.write(str(soup))\n",
    "\n",
    "    print(f\"HTML page updated and saved as {html_filepath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for ZTF17aaapufz\n",
      "Coordinates <SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (188.96783333, 27.93205556)>\n",
      "Date: None\n",
      "\n",
      "Looking for tile observation for T17t17\n",
      "Tile Found:\n",
      "T17t17 VLASS1.1v2\n",
      "https://archive-new.nrao.edu/vlass/quicklook/VLASS1.1v2/T17t17/\n",
      "https://archive-new.nrao.edu/vlass/quicklook/VLASS1.1v2/T17t17/VLASS1.1.ql.T17t17.J123340+273000.10.2048.v1/VLASS1.1.ql.T17t17.J123340+273000.10.2048.v1.I.iter1.image.pbcor.tt0.subim.fits\n",
      "PNG file images\\ZTF17aaapufz_VLASS1.1v2.png already exists. Skipping download.\n",
      "Run search completed in 0.33 seconds.\n",
      "\n",
      "Looking for tile observation for T17t17\n",
      "Tile Found:\n",
      "T17t17 VLASS2.1\n",
      "https://archive-new.nrao.edu/vlass/quicklook/VLASS2.1/T17t17/\n",
      "https://archive-new.nrao.edu/vlass/quicklook/VLASS2.1/T17t17/VLASS2.1.ql.T17t17.J123340+273000.10.2048.v1/VLASS2.1.ql.T17t17.J123340+273000.10.2048.v1.I.iter1.image.pbcor.tt0.subim.fits\n",
      "PNG file images\\ZTF17aaapufz_VLASS2.1.png already exists. Skipping download.\n",
      "Run search completed in 0.31 seconds.\n",
      "\n",
      "Looking for tile observation for T17t17\n",
      "Tile Found:\n",
      "T17t17 VLASS3.1\n",
      "https://archive-new.nrao.edu/vlass/quicklook/VLASS3.1/T17t17/\n",
      "https://archive-new.nrao.edu/vlass/quicklook/VLASS3.1/T17t17/VLASS3.1.ql.T17t17.J123340+273000.10.2048.v1/VLASS3.1.ql.T17t17.J123340+273000.10.2048.v1.I.iter1.image.pbcor.tt0.subim.fits\n",
      "PNG file images\\ZTF17aaapufz_VLASS3.1.png already exists. Skipping download.\n",
      "Run search completed in 0.30 seconds.\n",
      "Object #1 complete!\n",
      "{'name': 'ZTF17aaapufz', 'images': ['images\\\\ZTF17aaapufz_VLASS1.1v2.png', 'images\\\\ZTF17aaapufz_VLASS2.1.png', 'images\\\\ZTF17aaapufz_VLASS3.1.png', 'images\\\\ZTF17aaapufz_legsurv.png', 'images\\\\ZTF17aaapufz_ps1.png'], 'epochs': ['VLASS1.1v2', 'VLASS2.1', 'VLASS3.1'], 'vla_dates': [<Time object: scale='utc' format='iso' value=2017-11-24 00:00:00.000>, <Time object: scale='utc' format='iso' value=2020-09-06 00:00:00.000>, <Time object: scale='utc' format='iso' value=2023-02-12 00:00:00.000>], 'ztf_date': 1726.75}\n",
      "VLA JD Date: 2458081.5 (type: <class 'numpy.float64'>)\n",
      "VLA JD Date: 2459098.5 (type: <class 'numpy.float64'>)\n",
      "VLA JD Date: 2459987.5 (type: <class 'numpy.float64'>)\n",
      "ZTF JD Date: 2459726.75 (type: <class 'numpy.float64'>)\n",
      "Deltas: [-1645.25, -628.25, 260.75]\n",
      "Updating delta_t for image 0: -1645.25\n",
      "Updating delta_t for image 1: -628.25\n",
      "Updating delta_t for image 2: 260.75\n",
      "HTML page updated and saved as what.html\n"
     ]
    }
   ],
   "source": [
    "update_html_page(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for MAXI\n",
      "Coordinates <SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (182.5055, 49.94639056)>\n",
      "Date: None\n",
      "\n",
      "Looking for tile observation for T23t13\n",
      "Tile Found:\n",
      "T23t13 VLASS1.1v2\n",
      "https://archive-new.nrao.edu/vlass/quicklook/VLASS1.1v2/T23t13/\n",
      "https://archive-new.nrao.edu/vlass/quicklook/VLASS1.1v2/T23t13/VLASS1.1.ql.T23t13.J120908+493000.10.2048.v1/VLASS1.1.ql.T23t13.J120908+493000.10.2048.v1.I.iter1.image.pbcor.tt0.subim.fits\n",
      "PNG file images\\MAXI_VLASS1.1v2.png already exists. Skipping download.\n",
      "Run search completed in 0.25 seconds.\n",
      "\n",
      "Looking for tile observation for T23t13\n",
      "Tile Found:\n",
      "T23t13 VLASS2.1\n",
      "https://archive-new.nrao.edu/vlass/quicklook/VLASS2.1/T23t13/\n",
      "https://archive-new.nrao.edu/vlass/quicklook/VLASS2.1/T23t13/VLASS2.1.ql.T23t13.J120908+493000.10.2048.v1/VLASS2.1.ql.T23t13.J120908+493000.10.2048.v1.I.iter1.image.pbcor.tt0.subim.fits\n",
      "PNG file images\\MAXI_VLASS2.1.png already exists. Skipping download.\n",
      "Run search completed in 0.26 seconds.\n",
      "\n",
      "Looking for tile observation for T23t13\n",
      "Tile Found:\n",
      "T23t13 VLASS3.1\n",
      "https://archive-new.nrao.edu/vlass/quicklook/VLASS3.1/T23t13/\n",
      "https://archive-new.nrao.edu/vlass/quicklook/VLASS3.1/T23t13/VLASS3.1.ql.T23t13.J120908+493000.10.2048.v1/VLASS3.1.ql.T23t13.J120908+493000.10.2048.v1.I.iter1.image.pbcor.tt0.subim.fits\n",
      "PNG file images\\MAXI_VLASS3.1.png already exists. Skipping download.\n",
      "Run search completed in 0.26 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['images\\\\MAXI_VLASS1.1v2.png',\n",
       "  'images\\\\MAXI_VLASS2.1.png',\n",
       "  'images\\\\MAXI_VLASS3.1.png'],\n",
       " ['VLASS1.1v2', 'VLASS2.1', 'VLASS3.1'],\n",
       " [<Time object: scale='utc' format='iso' value=2017-11-20 00:00:00.000>,\n",
       "  <Time object: scale='utc' format='iso' value=2020-08-01 00:00:00.000>,\n",
       "  <Time object: scale='utc' format='iso' value=2023-02-04 00:00:00.000>])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import vlass_search\n",
    "\n",
    "maxi_ra = \"12h10m01.32s\"\n",
    "maxi_dec = \"+49d56m47.006s\"\n",
    "maxi = SkyCoord(ra = maxi_ra, dec = maxi_dec)\n",
    "\n",
    "vlass_search.run_search(\"MAXI\", maxi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded to: VLASS_dyn_summary.php\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'vlass_search' from 'd:\\\\summer_research_code\\\\Query_VLASS_2\\\\vlass_search.py'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(vlass_search)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
